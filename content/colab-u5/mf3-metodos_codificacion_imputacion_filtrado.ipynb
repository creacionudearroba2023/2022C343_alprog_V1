{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdpns4au6Z93"
      },
      "source": [
        "<img src=\"https://udearroba.udea.edu.co/imagescourses/2022C343_alprog_V1/banner-colab.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2zdHCLrdghz"
      },
      "source": [
        "# <font color='157699'> **Métodos de codificación**\n",
        "# <font color='157699'> **Métodos de imputación y filtrado**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yqIm2--i-0a"
      },
      "source": [
        "# <font color='157699'> **Métodos de codificación**\n",
        "\n",
        "### **Uso de Python para aplicar métodos como One-Hot encoding y Label encoding**\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Herramientas necesarias:**\n",
        "\n",
        "**a. Librerías:**\n",
        "- `Pandas`: facilita la manipulación de datos y estructuras de datos.\n",
        "- `sklearn.preprocessing`: contiene las herramientas necesarias para la codificación.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Label Encoding**\n",
        "\n",
        "**a. Creación del codificador**\n",
        "\n",
        "```python\n",
        "label_encoder = LabelEncoder()\n",
        "```\n",
        "\n",
        "**b. Aplicación a una columna categórica**\n",
        "\n",
        "Supongamos que tenemos un DataFrame `df` y una columna 'Categoria':\n",
        "\n",
        "```python\n",
        "df['Categoria_encoded'] = label_encoder.fit_transform(df['Categoria'])\n",
        "```\n",
        "\n",
        "**c. Inversión (de numérico a categórico)**\n",
        "\n",
        "```python\n",
        "df['Categoria'] = label_encoder.inverse_transform(df['Categoria_encoded'])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. One-Hot encoding**\n",
        "\n",
        "**a. Utilizando Pandas**\n",
        "\n",
        "Es la forma más sencilla de realizar One-Hot encoding:\n",
        "\n",
        "```python\n",
        "df_onehot = pd.get_dummies(df, columns=['Categoria'], prefix = ['Categoria'])\n",
        "```\n",
        "\n",
        "**b. Utilizando sklearn**\n",
        "\n",
        "**i. Creación del codificador**\n",
        "\n",
        "```python\n",
        "onehot_encoder = OneHotEncoder()\n",
        "```\n",
        "\n",
        "**ii. Transformación**\n",
        "\n",
        "```python\n",
        "onehot_encoded = onehot_encoder.fit_transform(df[['Categoria']]).toarray()\n",
        "```\n",
        "\n",
        "**iii. Agregando al DataFrame original**\n",
        "\n",
        "Para este ejemplo supongamos que las categorías son 'A', 'B', y 'C':\n",
        "\n",
        "```python\n",
        "df[['Categoria_A', 'Categoria_B', 'Categoria_C']] = pd.DataFrame(onehot_encoded, index=df.index)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Ventajas y vesventajas**\n",
        "\n",
        "**a. Label encoding**\n",
        "- **Ventajas**: no aumenta la dimensionalidad del conjunto de datos.\n",
        "- **Desventajas**: puede inducir un orden artificial en categorías sin orden inherente.\n",
        "\n",
        "**b. One-Hot encoding**\n",
        "- **Ventajas**: representa de forma clara las categorías sin introducir un orden artificial.\n",
        "- **Desventajas**: aumenta la dimensionalidad, lo que puede ser problemático para conjuntos de datos grandes.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Casos prácticos y ejemplos**\n",
        "\n",
        "Se puede demostrar con un conjunto de datos de muestra cómo se ven los datos antes y después de la codificación y discutir situaciones en las que sería más apropiado usar uno u otro método."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eycp7Pzgqvv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5_DYWurwEWC"
      },
      "source": [
        "# <font color='157699'> **Métodos de imputación y filtrado**\n",
        "\n",
        "### **Razones y métodos para la imputación de datos faltantes**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### **1. ¿Qué son los datos faltantes?**\n",
        "\n",
        "- **Definición**: son aquellos valores ausentes en un conjunto de datos que se supone deberían existir. Pueden surgir debido a errores humanos, fallos en sistemas de medición, no respuesta en encuestas, entre otros.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Impacto de los datos faltantes**\n",
        "\n",
        "**a. Sesgo en el análisis:** los datos faltantes pueden introducir un sesgo si no se tratan adecuadamente, lo que podría llevar a conclusiones erróneas.\n",
        "\n",
        "**b. Reducción de la eficiencia:** al eliminar registros con datos faltantes, se reduce el tamaño del conjunto de datos, lo que puede afectar la precisión y potencia de los análisis.\n",
        "\n",
        "**c. Problemas con algoritmos:** muchos algoritmos no pueden manejar datos faltantes por defecto y requieren un conjunto de datos completo para funcionar correctamente.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Tipos de datos faltantes**\n",
        "\n",
        "**a. MCAR (Missing Completely At Random):** la probabilidad de que falte un valor es independiente de cualquier otra observación o característica.\n",
        "\n",
        "**b. MAR (Missing At Random):** la probabilidad de que falte un valor está relacionada con alguna otra característica observada, pero no con el valor faltante en sí.\n",
        "\n",
        "**c. MNAR (Missing Not At Random):** la probabilidad de que falte un valor está relacionada con el valor faltante.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Métodos de imputación**\n",
        "\n",
        "**a. Eliminación:**  \n",
        "Eliminar registros con datos faltantes.\n",
        "\n",
        "- **Ventajas:** método simple y rápido.\n",
        "- **Desventajas:** pérdida de datos. Solo se recomienda cuando el porcentaje de datos faltantes es muy pequeño.\n",
        "\n",
        "**b. Imputación media/mediana/moda:**  \n",
        "Rellenar valores faltantes con la media (para variables continuas) o mediana/moda (para variables categóricas).\n",
        "\n",
        "- **Ventajas:** rápido y fácil de implementar.\n",
        "- **Desventajas:** puede distorsionar la distribución original y reducir la varianza.\n",
        "\n",
        "**c. Imputación por interpolación y extrapolación:**  \n",
        "Estima valores en función de otros puntos de datos (útil en series temporales).\n",
        "\n",
        "**d. Imputación por regresión:**  \n",
        "Usar otras características para predecir y completar el valor faltante.\n",
        "\n",
        "**e. K-NN Imputation:**  \n",
        "Rellenar valores faltantes utilizando los k vecinos más cercanos.\n",
        "\n",
        "- **Ventajas:** considera correlaciones entre variables.\n",
        "- **Desventajas:** computacionalmente costoso.\n",
        "\n",
        "**f. Métodos avanzados:**  \n",
        "MICE (Multiple Imputation by Chained Equations), imputación basada en modelos de árbol, imputación por aprendizaje profundo.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Elección del método de imputación**\n",
        "\n",
        "La elección del método de imputación depende de la naturaleza del conjunto de datos, la cantidad y el tipo de datos faltantes y el objetivo del análisis. Es fundamental validar el método elegido y considerar su impacto en los resultados finales.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Herramientas y librerías en Python**\n",
        "\n",
        "Ejemplo práctico utilizando Pandas para imputación básica y sklearn.impute para técnicas más avanzadas.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDK2ojoAkT9U"
      },
      "source": [
        "# <font color='157699'> **Métodos de imputación y filtrado**\n",
        "\n",
        "### **Técnicas de filtrado para limpieza y preprocesamiento de datos**\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Importancia del filtrado y la limpieza de datos**\n",
        "\n",
        "- **Relevancia en el análisis:** un conjunto de datos limpio mejora la precisión y confiabilidad del análisis.\n",
        "- **Ahorro de tiempo:** detectar y resolver problemas en las primeras etapas evita errores costosos y repetitivos más adelante.\n",
        "- **Mejora del rendimiento:** los algoritmos de *Machine Learning* y análisis estadístico funcionan mejor con datos limpios y bien estructurados.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Tipos de impurezas en los datos**\n",
        "\n",
        "**a. Valores faltantes:** ya discutidos en la sección anterior.\n",
        "**b. Outliers:** valores que se desvían significativamente del resto.\n",
        "**c. Duplicados:** registros repetidos en el conjunto de datos.\n",
        "**d. Errores de entrada:** resultado de errores humanos o de máquina al ingresar datos.\n",
        "**e. Datos irrelevantes:** información que no es pertinente para el análisis actual.\n",
        "**f. Inconsistencias:** datos que no siguen un patrón o estructura esperados.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Técnicas de filtrado**\n",
        "\n",
        "**a. Filtrado de outliers:**\n",
        "   - Métodos estadísticos (Z-score, IQR).\n",
        "   - Visualización (Box plots, scatter plots).\n",
        "\n",
        "**b. Eliminación de duplicados:**\n",
        "   - Uso de funciones en Pandas como drop_duplicates().\n",
        "\n",
        "**c. Corrección de errores de entrada:**\n",
        "   - Validación de datos utilizando reglas o patrones (por ejemplo, regex).\n",
        "   - Comparación con listas blancas / negras o bases de datos de referencia.\n",
        "\n",
        "**d. Eliminación de datos irrelevantes:**\n",
        "   - Selección de características basada en la relevancia para el análisis.\n",
        "   - Uso de métodos automáticos como la selección univariante de características.\n",
        "\n",
        "**e. Tratamiento de inconsistencias:**\n",
        "   - Normalización: convertir datos a una escala común.\n",
        "   - Estandarización: reescalar datos para tener una media de 0 y una desviación estándar de 1.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Herramientas y librerías en Python**\n",
        "\n",
        "- **Pandas:** funciones como dropna(), drop_duplicates(), replace(), entre otras.\n",
        "- **NumPy:** funciones para tratamiento estadístico y matemático.\n",
        "- **Scikit-learn:** herramientas para la selección de características, normalización y estandarización.\n",
        "- **Seaborn y Matplotlib:** para visualización y detección visual de *outliers* e inconsistencias.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Buenas prácticas en la limpieza de datos**\n",
        "\n",
        "**a. Documentar el proceso:** mantener un registro de todos los pasos realizados para referencias futuras y replicabilidad.\n",
        "**b. Validar cambios con el equipo o expertos en el dominio:** asegurarse de que las decisiones tomadas sean correctas y no eliminan información crítica.\n",
        "**c. Iterar y revisar:** la limpieza de datos suele ser un proceso iterativo. Revisar y refinar según sea necesario.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUw4UUPa6gmp"
      },
      "source": [
        "· Universidad de Antioquia · Ude@ Educación Virtual ·"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
